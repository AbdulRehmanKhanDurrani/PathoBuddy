# -*- coding: utf-8 -*-
"""infer_module.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a2bslEzB9onGfAxdRyhUY1FLMWjCyPRp
"""

# infer_module.py

from ocr_module import extract_text
from vision_module import caption_image
from llm_module import answer_question_from_text

def pathobuddy_infer(image_path: str, question: str) -> str:
    """
    Full PathoBuddy inference: image → context → answer.
    """
    # 1) Vision caption
    try:
        cap = caption_image(image_path)
    except Exception as e:
        cap = ""
        print(f"[vision_module error] {e}")

    # 2) OCR text
    try:
        ocr_txt = extract_text(image_path)
    except Exception as e:
        ocr_txt = ""
        print(f"[ocr_module error] {e}")

    # 3) Build context for QA
    parts = []
    if cap:
        parts.append(f"Image Caption: {cap}")
    if ocr_txt:
        parts.append(f"OCR Text: {ocr_txt}")
    context = "\n\n".join(parts).strip()

    if not context:
        raise RuntimeError("No context (caption or OCR) available for QA.")

    # 4) Ask the QA model
    answer = answer_question_from_text(context, question)
    return answer


if __name__ == "__main__":
    # Quick test
    img = "data/diagrams/sample_pathology_note.jpg"  # or your uploaded image
    q   = "What are the main symptoms described in this image’s text?"
    print("Answer:", pathobuddy_infer(img, q))